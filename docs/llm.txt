# Agent Orcha - LLM Documentation

## Project Overview

Agent Orcha is a declarative TypeScript framework for building, managing, and scaling multi-agent AI systems. It combines the flexibility of TypeScript with the simplicity of YAML to orchestrate complex workflows, manage diverse tools via Model Context Protocol (MCP), and integrate semantic search and knowledge graphs seamlessly.

**Repository:** https://github.com/ddalcu/agent-orcha
**NPM Package:** https://www.npmjs.com/package/agent-orcha
**Version:** 0.0.5
**License:** MIT
**Requirements:** Node.js >= 24.0.0

## Key Features

1. **Declarative AI**: Define agents, workflows, and infrastructure in version-controlled YAML files
2. **Model Agnostic**: Swap between OpenAI, Gemini, Anthropic, or local LLMs (Ollama, LM Studio) without code changes
3. **Universal Tooling**: Leverage Model Context Protocol (MCP) to connect agents to any external service, API, or database
4. **Knowledge Stores**: Unified SQLite + sqlite-vec persistence layer with optional direct graph mapping for semantic search and entity analysis
5. **ReAct Workflows**: Autonomous prompt-driven workflows with ReAct/single-turn modes, tool/agent discovery, and human-in-the-loop
6. **Robust Workflow Engine**: Orchestrate complex multi-agent sequences with parallel execution, conditional logic, and state management
7. **Agent Orcha Studio**: Built-in web dashboard with agent testing, knowledge browsing, workflow execution, MCP management, and in-browser IDE
8. **Conversation Memory**: Session-based memory with FIFO management and automatic TTL cleanup
9. **Structured Output**: JSON schema validation for agent responses
10. **Extensible Functions**: Custom JavaScript functions to extend agent capabilities with zero boilerplate
11. **AI-First Design**: YAML configurations are ideal for LLMs to read, write, and maintain

## Quick Start

### 1. Initialize Project

```bash
npx agent-orcha init my-project
cd my-project
```

This creates a project with:
- agents/ - Agent configuration files
- workflows/ - Workflow definition files
- functions/ - Custom JavaScript functions
- knowledge/ - Knowledge store configurations and data
- llm.json - LLM and embedding provider settings
- mcp.json - MCP server configuration

### 2. Configure LLM (llm.json)

```json
{
  "version": "1.0",
  "models": {
    "default": {
      "provider": "openai",
      "baseUrl": "http://localhost:1234/v1",
      "apiKey": "not-needed",
      "model": "your-model-name",
      "temperature": 0.7
    },
    "openai": {
      "apiKey": "sk-your-openai-key",
      "model": "gpt-4o",
      "temperature": 0.7
    }
  },
  "embeddings": {
    "default": {
      "provider": "openai",
      "baseUrl": "http://localhost:1234/v1",
      "apiKey": "not-needed",
      "model": "text-embedding-model"
    }
  }
}
```

**LLM Providers:**
- OpenAI: Omit baseUrl (uses default OpenAI endpoint)
- LM Studio: baseUrl: "http://localhost:1234/v1"
- Ollama: baseUrl: "http://localhost:11434/v1"
- Anthropic: Supported via provider configuration
- Gemini: Supported via provider configuration

### 3. Create Agent (agents/myagent.agent.yaml)

```yaml
name: myagent
description: My first AI agent
version: "1.0.0"

llm:
  name: default
  temperature: 0.7

prompt:
  system: |
    You are a helpful assistant.
    Answer questions clearly and concisely.
  inputVariables:
    - query

output:
  format: text
```

### 4. Start Server

```bash
npx agent-orcha start
# Server runs on http://localhost:3000
# Agent Orcha Studio available at http://localhost:3000
```

### 5. Invoke Agent

```bash
curl -X POST http://localhost:3000/api/agents/myagent/invoke \
  -H "Content-Type: application/json" \
  -d '{"input": {"query": "Hello, how are you?"}}'
```

Response:
```json
{
  "output": "Hello! I'm doing well, thank you...",
  "metadata": {
    "tokensUsed": 42,
    "toolCalls": [],
    "duration": 823
  }
}
```

## Core Concepts

### Agents

Agents are AI-powered units that use LLMs to process input and optionally call tools. Each agent is defined in a YAML file.

**Agent Schema:**
```yaml
name: string                    # Unique identifier (required)
description: string             # Human-readable description (required)
version: string                 # Semantic version (default: "1.0.0")

llm: string | object            # LLM configuration reference
  # Simple: llm: default
  # With override: llm: { name: default, temperature: 0.3 }

prompt:                         # Prompt configuration (required)
  system: string                # System message/instructions
  inputVariables: [string]      # Variables to interpolate in prompt

tools:                          # Available tools (optional)
  - mcp:<server-name>           # MCP server tools
  - knowledge:<store-name>      # Knowledge store search
  - function:<function-name>    # Custom functions
  - builtin:<tool-name>         # Built-in tools (e.g., ask_user)

output:                         # Output formatting (optional)
  format: text | json | structured
  schema:                       # Required when format is "structured"
    type: object
    properties:
      <field>:
        type: string | number | boolean | array | object
        description: string
        enum: [values]
    required: [field1, field2]

metadata:                       # Custom metadata (optional)
  category: string
  tags: [string]
```

**Example Agent with Tools:**
```yaml
name: researcher
description: Researches topics using web fetch and knowledge search
version: "1.0.0"

llm:
  name: default
  temperature: 0.5

prompt:
  system: |
    You are a thorough researcher.
    Use available tools to gather information before responding.
  inputVariables:
    - topic
    - context

tools:
  - mcp:fetch              # Web fetch MCP server
  - knowledge:docs         # Knowledge store search
  - function:custom-tool   # Custom function

output:
  format: text
```

**Agent with Structured Output:**
```yaml
name: sentiment-analyzer
description: Analyzes sentiment with structured output
version: "1.0.0"

llm:
  name: default
  temperature: 0

prompt:
  system: |
    Analyze the sentiment of the provided text.
  inputVariables:
    - text

output:
  format: structured
  schema:
    type: object
    properties:
      sentiment:
        type: string
        enum: [positive, negative, neutral]
      confidence:
        type: number
        minimum: 0
        maximum: 1
      keywords:
        type: array
        items:
          type: string
    required:
      - sentiment
      - confidence
```

### Conversation Memory

Agents automatically support conversation memory when a `sessionId` is provided in API calls. No agent-level configuration is required.

```bash
# First message in a session
curl -X POST http://localhost:3000/api/agents/chatbot/invoke \
  -H "Content-Type: application/json" \
  -d '{"input": {"message": "My name is Alice"}, "sessionId": "user-123"}'

# Follow-up message (agent remembers context)
curl -X POST http://localhost:3000/api/agents/chatbot/invoke \
  -H "Content-Type: application/json" \
  -d '{"input": {"message": "What is my name?"}, "sessionId": "user-123"}'
```

Memory settings (global, configured in orchestrator):
- `maxMessagesPerSession`: 50 (default) - FIFO eviction when exceeded
- `sessionTTL`: optional, in milliseconds - automatic cleanup of expired sessions

Session management endpoints:
- `GET /api/agents/sessions/stats` - Session statistics
- `GET /api/agents/sessions/:sessionId` - Get session details
- `DELETE /api/agents/sessions/:sessionId` - Clear session messages

### Workflows

Workflows orchestrate multiple agents. Two types are supported: step-based (`type: steps`) and ReAct (`type: react`).

#### Step-Based Workflows

Step-based workflows define explicit sequences with support for parallel execution, conditional logic, and state management.

**Workflow Schema:**
```yaml
name: string                    # Unique identifier (required)
description: string             # Human-readable description (required)
version: string                 # Semantic version (default: "1.0.0")
type: steps                     # Optional, "steps" is default

input:                          # Input schema (required)
  schema:
    <field_name>:
      type: string | number | boolean | array | object
      required: boolean
      default: any
      description: string

steps:                          # Workflow steps (required)
  - id: string                  # Unique step identifier
    agent: string               # Agent name to execute
    input:                      # Input mapping using templates
      <key>: "{{input.field}}"           # From workflow input
      <key>: "{{steps.stepId.output}}"   # From previous step
    condition: string           # Optional conditional execution
    retry:                      # Optional retry configuration
      maxAttempts: number       # Default: 3
      delay: number             # Milliseconds (default: 1000)
    output:
      key: string

  # Parallel execution
  - parallel:
      - id: step1
        agent: agent1
        input: {...}
      - id: step2
        agent: agent2
        input: {...}

config:                         # Workflow configuration (optional)
  timeout: number               # Total timeout ms (default: 300000)
  onError: stop | continue | retry

output:                         # Output mapping (required)
  <key>: "{{steps.stepId.output}}"

metadata:                       # Custom metadata (optional)
  category: string
  tags: [string]
```

**Template Syntax:**
- `{{input.fieldName}}` - Access workflow input field
- `{{steps.stepId.output}}` - Access step output
- `{{steps.stepId.output.nested.path}}` - Access nested output
- `{{steps.stepId.metadata.duration}}` - Access step metadata

**Example Step-Based Workflow:**
```yaml
name: research-paper
description: Research a topic and write a comprehensive paper
version: "1.0.0"

input:
  schema:
    topic:
      type: string
      required: true
      description: The topic to research
    style:
      type: string
      default: "professional"

steps:
  - id: research
    agent: researcher
    input:
      topic: "{{input.topic}}"
      context: "Gather comprehensive information"
    output:
      key: researchFindings

  - id: summarize
    agent: summarizer
    input:
      content: "{{steps.research.output}}"
      maxPoints: "10"
    condition: "{{steps.research.metadata.success}}"
    output:
      key: summary

  - id: write
    agent: writer
    input:
      research: "{{steps.research.output}}"
      outline: "{{steps.summarize.output}}"
      style: "{{input.style}}"
    output:
      key: paper

config:
  timeout: 600000
  onError: stop

output:
  paper: "{{steps.write.output}}"
  summary: "{{steps.summarize.output}}"
  researchFindings: "{{steps.research.output}}"
```

#### ReAct Workflows

Autonomous, prompt-driven workflows using the ReAct pattern. The agent decides which tools and agents to call based on the prompt.

**ReAct Schema:**
```yaml
name: string                    # Unique identifier (required)
description: string             # Human-readable description (required)
version: string                 # Semantic version (default: "1.0.0")
type: react                     # Required for ReAct workflows

input:                          # Input schema (required)
  schema:
    <field_name>:
      type: string | number | boolean | array | object
      required: boolean
      description: string

prompt:                         # Prompt configuration (required)
  system: string                # System message with instructions
  goal: string                  # Goal template (supports {{input.*}} interpolation)

graph:                          # ReAct configuration (required)
  model: string                 # LLM config name from llm.json

  executionMode: react | single-turn  # Default: react
  # react: Full ReAct loop, multiple rounds of tool calls
  # single-turn: Calls tools once and returns

  tools:                        # Tool discovery config
    mode: all | include | exclude | none  # Default: all
    sources:                    # Tool source types (default: all)
      - mcp
      - knowledge
      - function
      - builtin
    include: [string]           # Tool names to include (for mode: include)
    exclude: [string]           # Tool names to exclude (for mode: exclude)

  agents:                       # Agent discovery config
    mode: all | include | exclude | none  # Default: all
    include: [string]           # Agent names to include
    exclude: [string]           # Agent names to exclude

  maxIterations: number         # Max tool-calling iterations (default: 10)
  timeout: number               # Timeout in ms (default: 300000)

output:                         # Output extraction (required)
  <key>: "{{state.messages[-1].content}}"

config:                         # Workflow configuration (optional)
  onError: stop | continue | retry

metadata:                       # Custom metadata (optional)
  category: string
  tags: [string]
```

**Execution Modes:**

| Mode | Behavior | Best For |
|------|----------|----------|
| `single-turn` | Calls tools once, then returns | Research, data gathering, straightforward tasks |
| `react` | Multiple rounds of tool calls with reasoning | Complex multi-step problems, iterative analysis |

**Human-in-the-Loop:** ReAct workflows support the `builtin:ask_user` tool. When called, the workflow pauses and waits for user input. Include `builtin` in tool sources to enable it.

**Example ReAct Workflow:**
```yaml
name: react-research
description: Autonomous research using tool discovery
version: "1.0.0"
type: react

input:
  schema:
    topic:
      type: string
      required: true

prompt:
  system: |
    You are a research assistant with access to tools and agents.
    Identify all tools you need, call them in parallel, then synthesize results.
  goal: "Research and analyze: {{input.topic}}"

graph:
  model: default
  executionMode: single-turn
  tools:
    mode: all
    sources: [mcp, knowledge, function, builtin]
  agents:
    mode: all
  maxIterations: 10
  timeout: 300000

output:
  analysis: "{{state.messages[-1].content}}"
```

### Knowledge Stores

Knowledge stores enable semantic search and RAG capabilities. All stores use **SQLite with sqlite-vec** as the unified persistence layer — no external vector databases required. They are configured in `*.knowledge.yaml` files in the `knowledge/` directory. Optionally add a `graph.directMapping` section to build a knowledge graph from structured data.

**Knowledge Store Schema:**
```yaml
name: string                    # Unique identifier (required)
description: string             # Human-readable description (required)

source:                         # Data source (required)
  # Directory source
  type: directory
  path: string                  # Path relative to project root
  pattern: string               # Glob pattern for directories
  recursive: boolean            # Recursive search (default: true)

  # File source
  type: file
  path: string                  # Single file path

  # Database source
  type: database
  connectionString: string      # postgresql:// or mysql://
  query: string                 # SQL query
  contentColumn: string         # Column with content (default: "content")
  metadataColumns: [string]     # Columns for metadata
  batchSize: number             # Rows per batch (default: 100)

  # Web source
  type: web
  url: string                   # URL to scrape
  selector: string              # CSS selector (optional)
  headers:                      # Custom headers (optional)
    Authorization: "Bearer TOKEN"

loader:                         # Document loader (required)
  type: text | pdf | csv | json | markdown

splitter:                       # Text chunking (required)
  type: character | recursive | token | markdown
  chunkSize: number             # Characters per chunk (default: 1000)
  chunkOverlap: number          # Overlap between chunks (default: 200)

embedding: string               # Reference to embedding config (default: "default")

graph:                          # Optional — enables entity graph
  directMapping:                # Maps structured data to entities and relationships
    entities:
      - type: string            # Entity type name
        idColumn: string        # Column used as unique ID
        nameColumn: string      # Column used as display name (optional)
        properties: [string]    # Columns to include as entity properties
    relationships:              # Optional
      - type: string            # Relationship type name
        source: string          # Source entity type
        target: string          # Target entity type
        sourceIdColumn: string  # Column linking to source entity
        targetIdColumn: string  # Column linking to target entity

search:                         # Search configuration (optional)
  defaultK: number              # Results per search (default: 4)
  scoreThreshold: number        # Minimum similarity (0-1)
```

**How it works:**
- All data persists to SQLite at `.knowledge-data/{name}.db`
- On restart, source hashes are compared — if unchanged, data restores instantly without re-indexing
- Stores with `graph.directMapping` also store entities and relationships with vector embeddings
- Agents get additional graph tools (traverse, entity_lookup, graph_schema) when entities exist
- Search combines chunk KNN + entity KNN + neighborhood expansion, merged by score

**Example Vector-Only Store:**
```yaml
name: docs
description: Knowledge base for semantic search

source:
  type: directory
  path: knowledge/sample-data
  pattern: "*.txt"

loader:
  type: text

splitter:
  type: character
  chunkSize: 1000
  chunkOverlap: 200

embedding: default

search:
  defaultK: 4
  scoreThreshold: 0.2
```

**Example Store with Graph (Direct Mapping):**
```yaml
name: call-center-analysis
description: Call center data with agent/customer knowledge graph

source:
  type: database
  connectionString: postgresql://user:pass@localhost:5432/calls
  query: |
    SELECT c.id, c.transcript AS content, c.outcome,
           a.name AS agent_name, a.id AS agent_id,
           cu.name AS customer_name, cu.id AS customer_id
    FROM calls c
    JOIN agents a ON c.agent_id = a.id
    JOIN customers cu ON c.customer_id = cu.id
  contentColumn: content
  metadataColumns: [id, outcome, agent_name, agent_id, customer_name, customer_id]

loader:
  type: text

splitter:
  type: recursive
  chunkSize: 2000
  chunkOverlap: 200

embedding: default

graph:
  directMapping:
    entities:
      - type: Agent
        idColumn: agent_id
        nameColumn: agent_name
        properties: [agent_name]
      - type: Customer
        idColumn: customer_id
        nameColumn: customer_name
        properties: [customer_name]
      - type: Call
        idColumn: id
        nameColumn: id
        properties: [outcome]
    relationships:
      - type: HANDLED_BY
        source: Call
        target: Agent
        sourceIdColumn: id
        targetIdColumn: agent_id
      - type: MADE_BY
        source: Call
        target: Customer
        sourceIdColumn: id
        targetIdColumn: customer_id

search:
  defaultK: 10
```

### Functions

Functions are custom JavaScript tools that extend agent capabilities. They require no dependencies and are simple to create.

**Function Schema:**
```javascript
export default {
  name: 'function-name',           // Unique identifier (required)
  description: 'What it does',     // Clear description (required)

  parameters: {                    // Input parameters (required)
    param1: {
      type: 'number',              // string | number | boolean | array | object | enum
      description: 'Parameter description',
      required: true,              // Optional, defaults to true
      default: 0,                  // Optional default value
    },
  },

  execute: async ({ param1 }) => { // Execution function (required)
    // Your logic here
    return `Result: ${param1}`;
  },
};

// Optional metadata
export const metadata = {
  name: 'function-name',
  version: '1.0.0',
  author: 'Your Name',
  tags: ['category'],
};
```

**Example Function (Calculator):**
```javascript
export default {
  name: 'calculator',
  description: 'Performs basic arithmetic operations',

  parameters: {
    a: { type: 'number', description: 'First number' },
    b: { type: 'number', description: 'Second number' },
    operation: {
      type: 'enum',
      values: ['add', 'subtract', 'multiply', 'divide'],
      description: 'Operation to perform',
    },
  },

  execute: async ({ a, b, operation }) => {
    switch (operation) {
      case 'add': return `${a} + ${b} = ${a + b}`;
      case 'subtract': return `${a} - ${b} = ${a - b}`;
      case 'multiply': return `${a} * ${b} = ${a * b}`;
      case 'divide': return `${a} / ${b} = ${a / b}`;
    }
  },
};
```

**Using Functions in Agents:**
```yaml
name: math-assistant
description: Assistant that can perform calculations

llm:
  name: default
  temperature: 0.3

prompt:
  system: |
    You are a math assistant.
    Use the calculator tool to perform calculations.
  inputVariables:
    - query

tools:
  - function:calculator    # References calculator.function.js

output:
  format: text
```

### MCP Servers

Model Context Protocol (MCP) servers provide external tools to agents. Configure them in mcp.json.

**MCP Configuration:**
```json
{
  "version": "1.0.0",
  "servers": {
    "<server-name>": {
      "transport": "streamable-http | stdio | sse | sse-only",
      "url": "https://server-url/mcp",
      "headers": { "key": "value" },
      "command": "node",
      "args": ["./mcp-server.js"],
      "env": { "KEY": "VALUE" },
      "timeout": 30000,
      "enabled": true,
      "description": "Server description"
    }
  },
  "globalOptions": {
    "throwOnLoadError": false,
    "prefixToolNameWithServerName": true,
    "additionalToolNamePrefix": "",
    "defaultToolTimeout": 30000
  }
}
```

**Transport Types:**

| Transport | Use Case | Required Fields |
|-----------|----------|----------------|
| `stdio` | Local CLI tools | `command`, `args` |
| `streamable-http` | Remote HTTP servers | `url` |
| `sse` | Server-Sent Events | `url` |
| `sse-only` | SSE without HTTP fallback | `url` |

**Example MCP Configuration:**
```json
{
  "version": "1.0.0",
  "servers": {
    "fetch": {
      "transport": "streamable-http",
      "url": "https://remote.mcpservers.org/fetch/mcp",
      "description": "Web fetch capabilities",
      "timeout": 30000,
      "enabled": true
    },
    "filesystem": {
      "transport": "stdio",
      "command": "npx",
      "args": ["-y", "@modelcontextprotocol/server-filesystem", "/tmp"],
      "description": "File system access"
    }
  }
}
```

**Using MCP Tools in Agents:**
```yaml
tools:
  - mcp:fetch    # All tools from "fetch" server
```

### Agent Orcha Studio

Agent Orcha Studio is a built-in web dashboard available at `http://localhost:3000` when the server is running. It provides a visual interface for managing and testing your entire Agent Orcha setup.

**Studio Tabs:**

| Tab | Description |
|-----|-------------|
| **Agents** | Browse agents, invoke with custom input, stream responses, manage conversation sessions |
| **Knowledge** | Browse and search knowledge stores, view entities and graph structure for stores with direct mapping |
| **MCP** | Browse MCP servers, view available tools, call tools directly |
| **Workflows** | Browse and execute workflows (step-based and ReAct), stream execution progress |
| **Skills** | Browse and inspect available skills |
| **Monitor** | View LLM call logs with context size, token estimates, and duration metrics |
| **IDE** | In-browser file editor with file tree, syntax highlighting (YAML, JSON, JS), save with hot-reload |

## REST API Reference

### Health Check

```
GET /health

Response:
{
  "status": "ok",
  "timestamp": "2026-01-21T12:00:00.000Z"
}
```

### Agents Endpoints

**List All Agents**
```
GET /api/agents

Response:
[
  {
    "name": "agent1",
    "description": "Agent description",
    "version": "1.0.0",
    "tools": ["mcp:fetch", "knowledge:docs"]
  }
]
```

**Get Agent Details**
```
GET /api/agents/:name

Response:
{
  "name": "agent1",
  "description": "Agent description",
  "version": "1.0.0",
  "llm": { "name": "default", "temperature": 0.7 },
  "prompt": { "system": "...", "inputVariables": ["query"] },
  "tools": ["mcp:fetch"],
  "output": { "format": "text" }
}
```

**Invoke Agent**
```
POST /api/agents/:name/invoke
Content-Type: application/json

Request:
{
  "input": {
    "topic": "your topic",
    "context": "additional context"
  },
  "sessionId": "optional-session-id"
}

Response:
{
  "output": "Agent response text",
  "metadata": {
    "tokensUsed": 150,
    "toolCalls": ["fetch", "knowledge_search"],
    "duration": 1234,
    "sessionId": "optional-session-id",
    "messagesInSession": 2
  }
}
```

**Stream Agent Response (SSE)**
```
POST /api/agents/:name/stream
Content-Type: application/json

Request:
{
  "input": {
    "query": "your query"
  },
  "sessionId": "optional-session-id"
}

Response: Server-Sent Events stream with incremental output
```

**Session Statistics**
```
GET /api/agents/sessions/stats

Response:
{
  "activeSessions": 5,
  "totalMessages": 42
}
```

**Get Session Details**
```
GET /api/agents/sessions/:sessionId

Response:
{
  "sessionId": "user-123",
  "messages": [...],
  "messageCount": 10,
  "createdAt": 1706000000000,
  "lastAccessedAt": 1706001000000
}
```

**Delete Session**
```
DELETE /api/agents/sessions/:sessionId

Response:
{
  "success": true
}
```

### Workflows Endpoints

**List All Workflows**
```
GET /api/workflows

Response:
[
  {
    "name": "workflow1",
    "description": "Workflow description",
    "version": "1.0.0",
    "type": "steps"
  }
]
```

**Get Workflow Details**
```
GET /api/workflows/:name

Response:
{
  "name": "workflow1",
  "description": "Workflow description",
  "version": "1.0.0",
  "type": "steps",
  "input": { "schema": {...} },
  "steps": [...],
  "config": { "timeout": 300000 },
  "output": {...}
}
```

**Run Workflow**
```
POST /api/workflows/:name/run
Content-Type: application/json

Request:
{
  "input": {
    "topic": "research topic",
    "style": "professional"
  }
}

Response:
{
  "output": {
    "paper": "Final content",
    "summary": "Key points"
  },
  "metadata": {
    "duration": 5000,
    "stepsExecuted": 3,
    "success": true
  },
  "stepResults": {
    "research": { "output": "...", "metadata": {...} },
    "summarize": { "output": "...", "metadata": {...} }
  }
}
```

**Stream Workflow (SSE)**
```
POST /api/workflows/:name/stream
Content-Type: application/json

Request:
{
  "input": {
    "topic": "research topic"
  }
}

Response: Server-Sent Events stream with step progress updates
```

### Knowledge Endpoints

**List All Knowledge Stores**
```
GET /api/knowledge

Response:
[
  {
    "name": "docs",
    "description": "Knowledge base",
    "documentCount": 42
  }
]
```

**Get Knowledge Store Config**
```
GET /api/knowledge/:name

Response:
{
  "name": "docs",
  "description": "Knowledge base",
  "source": {...},
  "loader": {...},
  "splitter": {...},
  "search": {...}
}
```

**Search Knowledge Store**
```
POST /api/knowledge/:name/search
Content-Type: application/json

Request:
{
  "query": "search term",
  "k": 4
}

Response:
{
  "results": [
    {
      "content": "Document text...",
      "metadata": {...},
      "score": 0.92
    }
  ]
}
```

**Refresh Knowledge Store (Reload Documents)**
```
POST /api/knowledge/:name/refresh

Response:
{
  "success": true,
  "documentsLoaded": 42,
  "duration": 1234
}
```

**Add Documents to Knowledge Store**
```
POST /api/knowledge/:name/add
Content-Type: application/json

Request:
{
  "documents": [
    {
      "content": "Document text",
      "metadata": { "source": "custom" }
    }
  ]
}

Response:
{
  "success": true,
  "documentsAdded": 1
}
```

**Get Graph Entities**
```
GET /api/knowledge/:name/entities

Response:
[
  {
    "id": "entity-1",
    "type": "Person",
    "name": "Alice",
    "properties": {...}
  }
]
```

**Get Graph Edges**
```
GET /api/knowledge/:name/edges

Response:
[
  {
    "id": "edge-1",
    "type": "WORKS_WITH",
    "sourceId": "entity-1",
    "targetId": "entity-2"
  }
]
```

### LLM Endpoints

**List All LLM Configurations**
```
GET /api/llm

Response:
[
  {
    "name": "default",
    "model": "gpt-4o",
    "provider": "openai"
  }
]
```

**Get LLM Config**
```
GET /api/llm/:name
```

**Chat with LLM**
```
POST /api/llm/:name/chat
Content-Type: application/json

Request:
{
  "message": "Hello, how are you?"
}

Response:
{
  "output": "I'm doing well, thank you!"
}
```

**Stream LLM Chat (SSE)**
```
POST /api/llm/:name/stream
Content-Type: application/json

Request:
{
  "message": "Hello"
}

Response: Server-Sent Events stream
```

### Functions Endpoints

**List All Functions**
```
GET /api/functions

Response:
[
  {
    "name": "calculator",
    "description": "Performs arithmetic operations",
    "parameters": {...}
  }
]
```

**Get Function Details**
```
GET /api/functions/:name
```

**Call Function**
```
POST /api/functions/:name/call
Content-Type: application/json

Request:
{
  "arguments": {
    "a": 10,
    "b": 5,
    "operation": "add"
  }
}

Response:
{
  "result": "10 + 5 = 15"
}
```

### MCP Endpoints

**List MCP Servers**
```
GET /api/mcp

Response:
[
  {
    "name": "fetch",
    "description": "Web fetch capabilities",
    "transport": "streamable-http",
    "enabled": true
  }
]
```

**Get MCP Server Details**
```
GET /api/mcp/:name
```

**Get MCP Server Tools**
```
GET /api/mcp/:name/tools

Response:
[
  {
    "name": "fetch",
    "description": "Fetch a URL",
    "inputSchema": {...}
  }
]
```

**Call MCP Tool**
```
POST /api/mcp/:name/call
Content-Type: application/json

Request:
{
  "tool": "fetch",
  "arguments": {
    "url": "https://example.com"
  }
}

Response:
{
  "result": "..."
}
```

### Files Endpoints (IDE)

**Get File Tree**
```
GET /api/files/tree

Response:
{
  "tree": [
    {
      "name": "agents",
      "type": "directory",
      "children": [
        { "name": "example.agent.yaml", "type": "file" }
      ]
    }
  ]
}
```

**Read File**
```
GET /api/files/read?path=agents/example.agent.yaml

Response:
{
  "content": "name: example\n..."
}
```

**Write File**
```
PUT /api/files/write
Content-Type: application/json

Request:
{
  "path": "agents/example.agent.yaml",
  "content": "name: example\n..."
}

Response:
{
  "success": true
}
```

## CLI Reference

### Commands

**Initialize Project**
```bash
npx agent-orcha init [directory]

# Creates project structure with examples
# directory - Target directory (default: current)
```

**Start Server**
```bash
npx agent-orcha start

# Starts Fastify server on port 3000 (configurable via PORT env var)
# Agent Orcha Studio available at the same URL
# Environment variables:
#   PORT - Server port (default: 3000)
#   HOST - Server host (default: 0.0.0.0)
#   WORKSPACE - Base directory for config files (default: current directory)
```

**Help**
```bash
npx agent-orcha help

# Shows CLI usage information
```

## Library Usage

Agent Orcha can be used as a TypeScript/JavaScript library in your projects.

```typescript
import { Orchestrator } from 'agent-orcha';

const orchestrator = new Orchestrator({
  workspaceRoot: './my-agents-project'
});

await orchestrator.initialize();

// Invoke an agent
const result = await orchestrator.agents.invoke('researcher', {
  topic: 'machine learning',
  context: 'brief overview'
});

console.log(result.output);

// Invoke an agent with session memory
const chatResult = await orchestrator.agents.invoke(
  'chatbot',
  { message: 'Hello' },
  { sessionId: 'user-123' }
);

// Run a workflow
const workflowResult = await orchestrator.workflows.run('research-paper', {
  topic: 'artificial intelligence'
});

console.log(workflowResult.output);

// Search knowledge store
const searchResults = await orchestrator.knowledge.search('docs', {
  query: 'semantic search',
  k: 4
});

console.log(searchResults);

// Clean up
await orchestrator.close();
```

## Project Structure

```
my-project/
├── agents/                     # Agent YAML configurations
│   ├── researcher.agent.yaml
│   └── chatbot.agent.yaml
├── workflows/                  # Workflow YAML definitions
│   ├── research.workflow.yaml
│   └── react.workflow.yaml
├── functions/                  # Custom JavaScript functions
│   └── calculator.function.js
├── knowledge/                  # Knowledge store configs and data
│   ├── docs.knowledge.yaml
│   ├── graph.knowledge.yaml
│   └── sample-data/
│       └── documents.txt
├── llm.json                    # LLM and embedding configurations
├── mcp.json                    # MCP server configuration
├── .env                        # Environment variables (optional)
└── package.json                # Project metadata (if using as library)
```

## Environment Variables

```bash
# Server Configuration
PORT=3000                       # Server port (default: 3000)
HOST=0.0.0.0                   # Server host (default: 0.0.0.0)
WORKSPACE=./my-project    # Base directory for config files (default: current directory)
CORS_ORIGIN=true               # CORS origin policy (default: true)

# Note: LLM API keys are configured in llm.json, not via environment variables

# Database (for database knowledge sources when not in YAML)
DATABASE_URL=postgresql://user:pass@localhost:5432/db
MYSQL_URL=mysql://user:pass@localhost:3306/db
```

## Tool Types Reference

1. **MCP Tools** - External tools from MCP servers
   ```yaml
   tools:
     - mcp:fetch              # All tools from "fetch" server
     - mcp:filesystem         # All tools from "filesystem" server
   ```

2. **Knowledge Tools** - Semantic search on knowledge stores
   ```yaml
   tools:
     - knowledge:docs         # Search "docs" knowledge store
   ```

3. **Function Tools** - Custom JavaScript/TypeScript functions in functions/
   ```yaml
   tools:
     - function:calculator
     - function:fibonacci
   ```

4. **Built-in Tools** - Framework-provided tools
   ```yaml
   tools:
     - builtin:ask_user       # Human-in-the-loop (ReAct workflows)
     - builtin:memory_save    # Save to persistent memory
   ```

5. **Sandbox Tools** - Sandboxed code execution
   ```yaml
   tools:
     - sandbox:exec           # Execute code in sandbox
     - sandbox:web_fetch      # Fetch URLs from sandbox
     - sandbox:web_search     # Web search from sandbox
   ```

6. **Project Tools** - Workspace file access
   ```yaml
   tools:
     - project:read           # Read project files
     - project:write          # Write project files
   ```

## Production Deployment

### Docker Deployment

```dockerfile
FROM node:24-slim
WORKDIR /app
COPY package*.json ./
RUN npm ci --only=production
COPY . .
EXPOSE 3000
CMD ["npx", "agent-orcha", "start"]
```

### Configuration Best Practices

1. **LLM Configuration**: Store API keys in environment variables, not in llm.json
2. **Knowledge Stores**: All stores use SQLite — data persists automatically to `.knowledge-data/`
3. **Timeouts**: Configure appropriate timeouts for workflows based on expected duration
4. **Error Handling**: Set onError strategy in workflows (stop, continue, retry)

## Examples

### Example 1: Simple Q&A Agent

```yaml
# agents/qa.agent.yaml
name: qa
description: Question answering agent
version: "1.0.0"

llm:
  name: default
  temperature: 0.3

prompt:
  system: |
    You are a helpful Q&A assistant.
    Provide concise, accurate answers to questions.
  inputVariables:
    - question

output:
  format: text
```

### Example 2: Research Agent with Knowledge Search

```yaml
# agents/researcher.agent.yaml
name: researcher
description: Research agent with web fetch and knowledge search
version: "1.0.0"

llm:
  name: default
  temperature: 0.5

prompt:
  system: |
    You are a thorough researcher.
    1. Search the knowledge base first
    2. Fetch additional information from the web if needed
    3. Synthesize findings into a comprehensive report
  inputVariables:
    - topic
    - context

tools:
  - mcp:fetch
  - knowledge:docs

output:
  format: text
```

### Example 3: Multi-Step Workflow

```yaml
# workflows/analysis.workflow.yaml
name: analysis
description: Multi-step data analysis workflow
version: "1.0.0"

input:
  schema:
    data:
      type: string
      required: true

steps:
  - id: extract
    agent: extractor
    input:
      data: "{{input.data}}"
    output:
      key: extracted

  - id: analyze
    agent: analyzer
    input:
      data: "{{steps.extract.output}}"
    output:
      key: analysis

  - id: summarize
    agent: summarizer
    input:
      analysis: "{{steps.analyze.output}}"
    output:
      key: summary

config:
  timeout: 300000
  onError: stop

output:
  summary: "{{steps.summarize.output}}"
  fullAnalysis: "{{steps.analyze.output}}"
```

### Example 4: ReAct Autonomous Workflow

```yaml
# workflows/autonomous.workflow.yaml
name: autonomous-research
description: Autonomous research using ReAct
version: "1.0.0"
type: react

input:
  schema:
    topic:
      type: string
      required: true

prompt:
  system: |
    You are a research assistant with access to tools and agents.
    Use available tools to gather information, then synthesize a comprehensive report.
  goal: "Research and provide a thorough analysis of: {{input.topic}}"

graph:
  model: default
  executionMode: react
  tools:
    mode: all
    sources: [mcp, knowledge, function, builtin]
  agents:
    mode: all
  maxIterations: 10
  timeout: 300000

output:
  analysis: "{{state.messages[-1].content}}"
```

### Example 5: Agent with Structured Output

```yaml
# agents/data-extractor.agent.yaml
name: data-extractor
description: Extracts structured data from text
version: "1.0.0"

llm:
  name: default
  temperature: 0

prompt:
  system: |
    Extract structured information from the provided text.
  inputVariables:
    - text

output:
  format: structured
  schema:
    type: object
    properties:
      people:
        type: array
        items:
          type: object
      locations:
        type: array
        items:
          type: string
      dates:
        type: array
        items:
          type: string
    required:
      - people
      - locations
```

### Example 6: Knowledge Store with Graph (Direct Mapping)

```yaml
# knowledge/org-chart.knowledge.yaml
name: org-chart
description: Organization chart with employee/department graph

source:
  type: database
  connectionString: postgresql://user:pass@localhost:5432/hr
  query: |
    SELECT e.id, e.name, e.title, e.bio AS content,
           d.name AS dept_name, d.id AS dept_id
    FROM employees e
    JOIN departments d ON e.department_id = d.id
  contentColumn: content
  metadataColumns: [id, name, title, dept_name, dept_id]

loader:
  type: text

splitter:
  type: recursive
  chunkSize: 2000
  chunkOverlap: 200

embedding: default

graph:
  directMapping:
    entities:
      - type: Employee
        idColumn: id
        nameColumn: name
        properties: [name, title]
      - type: Department
        idColumn: dept_id
        nameColumn: dept_name
        properties: [dept_name]
    relationships:
      - type: WORKS_IN
        source: Employee
        target: Department
        sourceIdColumn: id
        targetIdColumn: dept_id

search:
  defaultK: 10
```

## Troubleshooting

### Common Issues

1. **LLM Connection Errors**
   - Verify API keys in llm.json or environment variables
   - Check baseUrl for local models (LM Studio, Ollama)
   - Ensure model name matches provider configuration

2. **Knowledge Store Errors**
   - Check embedding model configuration in llm.json
   - Ensure source documents exist at specified paths
   - Verify SQLite write permissions for `.knowledge-data/` directory

3. **MCP Server Errors**
   - Verify MCP server is accessible at specified URL
   - Check timeout configuration
   - Review MCP server logs for errors

4. **Workflow Execution Errors**
   - Check step dependencies and template syntax
   - Verify agent names referenced in steps exist
   - Review timeout configuration for long-running workflows
   - For ReAct: Check maxIterations to prevent runaway loops

5. **Session/Memory Issues**
   - Ensure consistent sessionId across requests
   - Check session TTL hasn't expired
   - Memory is in-process; sessions are lost on server restart

## Additional Resources

- **Documentation:** https://ddalcu.github.io/agent-orcha/documentation.html
- **GitHub Repository:** https://github.com/ddalcu/agent-orcha
- **NPM Package:** https://www.npmjs.com/package/agent-orcha
- **Issue Tracker:** https://github.com/ddalcu/agent-orcha/issues
- **Discussions:** https://github.com/ddalcu/agent-orcha/discussions

## Version History

- **0.0.5** (Current)
  - LangChain removed — replaced with custom implementations and direct LLM provider SDKs
  - Node.js 24+ required (built-in TypeScript support)
  - Unified SQLite + sqlite-vec knowledge stores (Chroma/Pinecone/Qdrant/Neo4j/S3 removed)
  - ReAct workflows replace LangGraph workflows
  - Skills system, task management, sandbox execution, integrations, triggers, persistent memory
  - Custom LLM providers (OpenAI, Anthropic, Gemini)
  - Knowledge graph tools (entity_lookup, traverse, graph_schema, sql, search)
  - Direct SQL-to-graph mapping (DirectMapper)
  - LLM call observability (LLMCallLogger)
  - New UI views (Monitor, Skills)
  - CI/CD (GitHub Actions), 100+ test files

- **0.0.3**
  - Knowledge stores replace vector stores
  - LangGraph autonomous workflows
  - Agent Orcha Studio web dashboard
  - Conversation memory, structured output
  - New data sources: database, S3, web scraping

- **0.0.2**
  - Streaming improvements
  - Bug fixes and stability

- **0.0.1** (Initial Release)
  - Declarative YAML-based agent configuration
  - Multi-agent workflow orchestration
  - MCP server support, custom function tools
  - REST API with SSE streaming
  - CLI and web UI

---

Last Updated: 2026-02-23
